{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "프로젝트 초기 설정 및 개발 환경 구성",
        "description": "Next.js 기반 프론트엔드와 FastAPI 백엔드 프로젝트 구조 설정, 필수 의존성 설치, 개발 환경 구성",
        "details": "1. Next.js 14 프로젝트 생성 (TypeScript, Tailwind CSS, App Router)\n2. FastAPI 백엔드 프로젝트 구조 설정\n3. 필수 패키지 설치:\n   - Frontend: react, next, typescript, @vercel/ai, tailwindcss, lucide-react, @radix-ui/react-*, class-variance-authority, clsx, tailwind-merge\n   - Backend: fastapi, uvicorn, langchain, langchain-openai, pinecone-client, python-dotenv, pydantic\n4. 환경 변수 설정 (.env): OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENV\n5. Docker 개발 환경 구성 (docker-compose.yml)\n6. Git 저장소 초기화 및 .gitignore 설정",
        "testStrategy": "1. 프로젝트 의존성 설치 검증 (npm install, pip install)\n2. Next.js 개발 서버 실행 테스트 (npm run dev)\n3. FastAPI 서버 실행 테스트 (uvicorn main:app --reload)\n4. 환경 변수 로드 검증\n5. TypeScript 컴파일 에러 체크",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "LangChain 기반 Core Agent 구현",
        "description": "ReAct 패턴을 사용하는 자율적 연구 에이전트의 핵심 로직 구현",
        "details": "1. LangChain ReAct Agent 설정:\n```python\nfrom langchain.agents import create_react_agent\nfrom langchain_openai import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\n\nllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\nreact_prompt = PromptTemplate.from_template('''\nYou are a research assistant. Use the following format:\nThought: reasoning about what to do\nAction: the action to take\nAction Input: the input to the action\nObservation: the result\n... (repeat N times)\nFinal Answer: the final answer\n\nQuestion: {input}\nThought: {agent_scratchpad}\n''')\n\nagent = create_react_agent(llm, tools=[], prompt=react_prompt)\n```\n2. Agent Executor 구현\n3. Memory 관리 (ConversationSummaryMemory)\n4. Reasoning Chain 로깅 시스템\n5. Agent 상태 관리 및 에러 핸들링",
        "testStrategy": "1. 단순 질문-답변 테스트\n2. 다단계 추론 과정 검증\n3. Memory 지속성 테스트\n4. 에러 상황 처리 검증 (API 실패, 타임아웃)\n5. 추론 체인 로깅 정확성 확인",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "LangChain ReAct Agent 초기 설정 구현",
            "description": "LangChain의 ReAct 패턴을 사용하여 기본 에이전트 구조를 설정하고 프롬프트 템플릿을 구성",
            "dependencies": [],
            "details": "src/agents/core_agent.py 파일을 생성하고 LangChain ReAct Agent의 기본 설정을 구현합니다. ChatOpenAI 모델 초기화, ReAct 프롬프트 템플릿 정의, create_react_agent 함수를 사용한 에이전트 생성 로직을 포함합니다. 환경 변수에서 API 키를 로드하고, 모델 파라미터(temperature, max_tokens 등)를 설정 가능하도록 구성합니다.",
            "status": "done",
            "testStrategy": "프롬프트 템플릿이 올바르게 포맷되는지 확인하고, 에이전트 인스턴스가 정상적으로 생성되는지 단위 테스트 작성"
          },
          {
            "id": 2,
            "title": "Agent Executor 및 Tool Integration 구현",
            "description": "에이전트가 사용할 도구들을 통합하고 Agent Executor를 구성하여 실행 환경 설정",
            "dependencies": [],
            "details": "LangChain의 AgentExecutor를 설정하여 에이전트가 도구를 사용할 수 있도록 구현합니다. 초기에는 더미 도구들(예: Calculator, Search)을 생성하고, 추후 실제 도구로 교체할 수 있는 구조로 설계합니다. max_iterations, early_stopping_method 등의 실행 파라미터를 설정하고, verbose 모드를 통해 실행 과정을 추적할 수 있도록 합니다.",
            "status": "done",
            "testStrategy": "더미 도구를 사용한 간단한 태스크 실행 테스트, 도구 호출이 올바르게 로깅되는지 확인"
          },
          {
            "id": 3,
            "title": "Memory 관리 시스템 구현",
            "description": "ConversationSummaryMemory를 활용한 대화 기록 관리 및 컨텍스트 유지 시스템 구축",
            "dependencies": [],
            "details": "LangChain의 ConversationSummaryMemory를 구현하여 긴 대화에서도 중요한 정보를 유지할 수 있도록 합니다. 메모리 버퍼 크기 설정, 요약 생성 로직, 메모리 저장/로드 기능을 포함합니다. Redis나 파일 시스템을 사용한 영구 저장 옵션도 구현하여 세션 간 메모리 유지가 가능하도록 합니다.",
            "status": "done",
            "testStrategy": "메모리에 대화 추가/검색 테스트, 요약 생성 품질 확인, 영구 저장소 연동 테스트"
          },
          {
            "id": 4,
            "title": "Reasoning Chain 로깅 시스템 구현",
            "description": "에이전트의 사고 과정과 액션을 추적하고 기록하는 상세 로깅 시스템 구축",
            "dependencies": [],
            "details": "에이전트의 Thought-Action-Observation 사이클을 캡처하고 구조화된 형태로 저장하는 로깅 시스템을 구현합니다. 각 추론 단계에 타임스탬프, 단계 번호, 사용된 도구, 입력/출력 데이터를 기록합니다. JSON 형식으로 로그를 저장하고, 추후 분석이나 디버깅에 활용할 수 있도록 쿼리 인터페이스도 제공합니다.",
            "status": "done",
            "testStrategy": "다양한 시나리오에서 로깅이 정확히 이루어지는지 확인, 로그 데이터 구조 검증"
          },
          {
            "id": 5,
            "title": "Agent 상태 관리 및 에러 핸들링 구현",
            "description": "에이전트의 실행 상태를 관리하고 다양한 에러 상황을 처리하는 견고한 시스템 구축",
            "dependencies": [],
            "details": "에이전트의 상태(idle, running, error, completed)를 추적하는 상태 머신을 구현합니다. API 호출 실패, 도구 실행 오류, 무한 루프 감지 등 다양한 에러 시나리오에 대한 처리 로직을 구현합니다. 재시도 메커니즘, 백오프 전략, 그레이스풀 셧다운을 포함하여 안정적인 운영이 가능하도록 합니다. 에러 발생 시 상세한 컨텍스트와 함께 로깅하고, 복구 가능한 에러의 경우 자동 복구를 시도합니다.",
            "status": "done",
            "testStrategy": "다양한 에러 시나리오 시뮬레이션, 상태 전환 정확성 검증, 복구 메커니즘 테스트"
          }
        ]
      },
      {
        "id": 3,
        "title": "Vercel AI SDK 기반 채팅 인터페이스 구현",
        "description": "Next.js와 Vercel AI SDK를 사용한 스트리밍 채팅 UI 구현",
        "details": "1. API Route 설정 (app/api/chat/route.ts):\n```typescript\nimport { streamText } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  \n  const result = await streamText({\n    model: openai('gpt-4o-mini'),\n    messages,\n  });\n  \n  return result.toAIStreamResponse();\n}\n```\n2. useChat hook 구현 (app/page.tsx)\n3. shadcn/ui 컴포넌트 설정 (Button, Input, Card, ScrollArea)\n4. 메시지 컴포넌트 구현 (user/assistant 구분)\n5. 스트리밍 응답 처리\n6. 로딩 상태 및 에러 처리 UI",
        "testStrategy": "1. 메시지 전송/수신 기능 테스트\n2. 스트리밍 응답 실시간 렌더링 검증\n3. UI 컴포넌트 렌더링 테스트\n4. 사용자 입력 검증 (빈 메시지, 긴 메시지)\n5. 네트워크 에러 처리 UI 테스트",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "API Route 설정 및 OpenAI 연동 구현",
            "description": "Vercel AI SDK를 사용하여 Next.js API Route에서 OpenAI와 통신하는 스트리밍 엔드포인트 구현",
            "dependencies": [],
            "details": "app/api/chat/route.ts 파일을 생성하고 streamText 함수를 사용하여 OpenAI API와 연동합니다. POST 요청을 처리하며, 요청 본문에서 messages 배열을 추출하고, OpenAI의 gpt-4o-mini 모델로 스트리밍 응답을 생성합니다. 환경 변수에서 OPENAI_API_KEY를 읽어 인증을 처리하고, 에러 처리를 위한 try-catch 블록을 구현합니다.",
            "status": "pending",
            "testStrategy": "API Route에 대한 POST 요청 테스트, 스트리밍 응답 검증, 잘못된 요청 형식에 대한 에러 처리 테스트"
          },
          {
            "id": 2,
            "title": "shadcn/ui 컴포넌트 설정 및 설치",
            "description": "채팅 인터페이스에 필요한 shadcn/ui 컴포넌트들을 설치하고 설정",
            "dependencies": [],
            "details": "npx shadcn-ui@latest init 명령어로 shadcn/ui를 초기화하고, Button, Input, Card, ScrollArea 컴포넌트를 설치합니다. components.json 설정 파일을 생성하고, 각 컴포넌트를 npx shadcn-ui@latest add [component-name] 명령어로 추가합니다. globals.css에 필요한 CSS 변수들이 추가되었는지 확인하고, 다크 모드 지원을 위한 설정을 포함합니다.",
            "status": "in-progress",
            "testStrategy": "각 컴포넌트의 렌더링 테스트, 스타일 적용 확인, 접근성 테스트"
          },
          {
            "id": 3,
            "title": "메시지 컴포넌트 및 채팅 UI 레이아웃 구현",
            "description": "사용자와 AI 메시지를 구분하여 표시하는 메시지 컴포넌트와 전체 채팅 레이아웃 구현",
            "dependencies": [
              2
            ],
            "details": "components/Message.tsx를 생성하여 role (user/assistant)에 따라 다른 스타일을 적용하는 메시지 컴포넌트를 구현합니다. 사용자 메시지는 우측 정렬, AI 메시지는 좌측 정렬로 표시하고, 각각 다른 배경색을 적용합니다. ScrollArea 컴포넌트를 사용하여 메시지 목록을 스크롤 가능하게 만들고, 새 메시지가 추가될 때 자동으로 하단으로 스크롤되도록 구현합니다. Card 컴포넌트로 전체 채팅 인터페이스를 감싸 깔끔한 UI를 제공합니다.",
            "status": "pending",
            "testStrategy": "메시지 컴포넌트 단위 테스트, 다양한 메시지 길이에 대한 레이아웃 테스트, 스크롤 동작 검증"
          },
          {
            "id": 4,
            "title": "useChat Hook 통합 및 입력 폼 구현",
            "description": "Vercel AI SDK의 useChat hook을 사용하여 채팅 기능을 구현하고 메시지 입력 폼 생성",
            "dependencies": [
              1,
              3
            ],
            "details": "app/page.tsx에서 useChat hook을 import하고 messages, input, handleInputChange, handleSubmit, isLoading 등의 상태와 함수를 사용합니다. Input 컴포넌트와 Button 컴포넌트를 사용하여 메시지 입력 폼을 구현하고, 폼 제출 시 handleSubmit을 호출합니다. 입력 필드는 value와 onChange로 제어되며, 메시지 전송 중에는 입력 필드와 버튼을 비활성화합니다. Enter 키로도 메시지를 전송할 수 있도록 onKeyPress 이벤트를 처리합니다.",
            "status": "pending",
            "testStrategy": "useChat hook 동작 테스트, 폼 제출 및 상태 업데이트 검증, 키보드 이벤트 처리 테스트"
          },
          {
            "id": 5,
            "title": "스트리밍 응답 처리 및 로딩/에러 상태 UI 구현",
            "description": "실시간 스트리밍 응답을 화면에 표시하고 로딩 및 에러 상태를 처리하는 UI 구현",
            "dependencies": [
              4
            ],
            "details": "useChat hook의 isLoading 상태를 사용하여 로딩 인디케이터를 표시합니다. AI가 응답을 생성하는 동안 '...' 애니메이션이나 스피너를 표시하고, 스트리밍으로 들어오는 텍스트를 실시간으로 메시지 컴포넌트에 렌더링합니다. error 상태를 처리하여 네트워크 오류나 API 오류 발생 시 사용자에게 친화적인 에러 메시지를 표시합니다. 재시도 버튼을 제공하여 실패한 요청을 다시 시도할 수 있도록 구현합니다.",
            "status": "pending",
            "testStrategy": "스트리밍 텍스트 렌더링 테스트, 로딩 상태 전환 검증, 에러 시나리오별 UI 테스트, 재시도 기능 테스트"
          },
          {
            "id": 6,
            "title": "채팅 API Route 구현 및 OpenAI 연동 설정",
            "description": "Vercel AI SDK를 사용하여 Next.js API Route에서 OpenAI와 통신하고 스트리밍 응답을 처리하는 백엔드 엔드포인트 구현",
            "dependencies": [],
            "details": "app/api/chat/route.ts 파일을 생성하고 Vercel AI SDK의 streamText 함수를 사용하여 OpenAI API와 연동합니다. POST 요청을 처리하여 messages 배열을 받아 GPT-4o-mini 모델로 전달하고, 스트리밍 응답을 toAIStreamResponse()로 변환하여 반환합니다. OPENAI_API_KEY 환경 변수 설정과 에러 핸들링(API 키 누락, 네트워크 오류 등)을 포함합니다.",
            "status": "pending",
            "testStrategy": "API Route 직접 호출 테스트, 스트리밍 응답 형식 검증, 에러 상황(잘못된 요청, API 키 오류) 처리 확인"
          },
          {
            "id": 7,
            "title": "shadcn/ui 컴포넌트 설정 및 UI 기본 구조 구현",
            "description": "채팅 인터페이스에 필요한 shadcn/ui 컴포넌트들을 설치하고 기본 레이아웃 구조를 구성",
            "dependencies": [],
            "details": "npx shadcn-ui@latest add button input card scroll-area 명령으로 필요한 컴포넌트를 설치합니다. app/page.tsx에 기본 레이아웃을 구성하여 Card 컴포넌트로 채팅 컨테이너를 만들고, ScrollArea로 메시지 영역을, 하단에 Input과 Button으로 입력 영역을 배치합니다. Tailwind CSS 클래스로 반응형 디자인과 적절한 spacing을 적용합니다.",
            "status": "pending",
            "testStrategy": "컴포넌트 렌더링 테스트, 반응형 레이아웃 확인, 스크롤 영역 동작 검증"
          },
          {
            "id": 8,
            "title": "메시지 컴포넌트 구현 및 스타일링",
            "description": "사용자와 AI 메시지를 구분하여 표시하는 재사용 가능한 메시지 컴포넌트 개발",
            "dependencies": [
              7
            ],
            "details": "components/message.tsx 파일을 생성하여 Message 컴포넌트를 구현합니다. role(user/assistant)에 따라 다른 스타일(정렬, 색상, 아이콘)을 적용하고, 메시지 내용을 표시합니다. Lucide React 아이콘(User, Bot)을 사용하여 시각적 구분을 제공하고, cn() 유틸리티로 조건부 스타일링을 적용합니다. 타임스탬프 표시와 마크다운 렌더링 지원을 고려합니다.",
            "status": "pending",
            "testStrategy": "다양한 메시지 타입 렌더링 테스트, 긴 메시지 처리 확인, 스타일 일관성 검증"
          },
          {
            "id": 9,
            "title": "useChat Hook 통합 및 상태 관리 구현",
            "description": "Vercel AI SDK의 useChat Hook을 사용하여 채팅 상태 관리와 API 통신 로직 구현",
            "dependencies": [
              6,
              8
            ],
            "details": "app/page.tsx에서 useChat Hook을 import하고 messages, input, handleInputChange, handleSubmit, isLoading 등의 상태와 함수를 활용합니다. ScrollArea 내부에 messages.map()으로 Message 컴포넌트들을 렌더링하고, form의 onSubmit에 handleSubmit을 연결합니다. Input의 value와 onChange를 Hook과 연결하고, isLoading 상태에 따라 버튼을 비활성화합니다. 자동 스크롤 기능을 useEffect로 구현합니다.",
            "status": "pending",
            "testStrategy": "메시지 전송/수신 플로우 테스트, Hook 상태 동기화 확인, 폼 제출 동작 검증"
          },
          {
            "id": 10,
            "title": "스트리밍 응답 처리 및 사용자 경험 최적화",
            "description": "실시간 스트리밍 응답 표시, 로딩 상태, 에러 처리 등 UX 개선 사항 구현",
            "dependencies": [
              9
            ],
            "details": "스트리밍 중인 AI 응답을 실시간으로 표시하기 위해 Message 컴포넌트에 isStreaming prop을 추가하고 타이핑 애니메이션을 구현합니다. useChat의 error 상태를 활용하여 에러 메시지를 표시하고, 재시도 버튼을 제공합니다. 메시지 전송 중 입력 필드 포커스 유지, Enter 키 전송 지원, 빈 메시지 전송 방지 등의 UX 개선사항을 적용합니다. 스켈레톤 로더나 펄스 애니메이션으로 로딩 상태를 시각화합니다.",
            "status": "pending",
            "testStrategy": "스트리밍 애니메이션 동작 확인, 에러 상황 UI 테스트, 키보드 단축키 동작 검증, 접근성 테스트"
          }
        ]
      },
      {
        "id": 4,
        "title": "LangChain 문서 처리 파이프라인 구현",
        "description": "PDF와 웹 문서를 처리하고 벡터화하는 RAG 파이프라인 구축",
        "details": "1. Document Loader 구현:\n```python\nfrom langchain.document_loaders import PyPDFLoader, WebBaseLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\ndef process_document(file_path: str, doc_type: str):\n    if doc_type == 'pdf':\n        loader = PyPDFLoader(file_path)\n    elif doc_type == 'web':\n        loader = WebBaseLoader(file_path)\n    \n    documents = loader.load()\n    \n    splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200,\n        separators=['\\n\\n', '\\n', '.', ' ']\n    )\n    \n    chunks = splitter.split_documents(documents)\n    return chunks\n```\n2. 메타데이터 추출 및 관리\n3. 문서 타입별 최적화된 처리 전략\n4. Chunk 품질 검증 로직\n5. 문서 업로드 API 엔드포인트",
        "testStrategy": "1. PDF 파일 처리 테스트 (다양한 크기/형식)\n2. 웹페이지 스크래핑 정확성 검증\n3. Chunking 품질 테스트 (중복, 누락 확인)\n4. 메타데이터 추출 정확성 테스트\n5. 대용량 문서 처리 성능 테스트",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Pinecone 벡터 데이터베이스 통합",
        "description": "OpenAI 임베딩과 Pinecone을 사용한 벡터 스토어 구현 및 검색 시스템 구축",
        "details": "1. Pinecone 초기화 및 인덱스 생성:\n```python\nimport pinecone\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_pinecone import PineconeVectorStore\n\npinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n\nif 'research-assistant' not in pinecone.list_indexes():\n    pinecone.create_index(\n        'research-assistant',\n        dimension=1536,  # OpenAI embedding dimension\n        metric='cosine'\n    )\n\nembeddings = OpenAIEmbeddings(model='text-embedding-3-small')\nvectorstore = PineconeVectorStore(\n    index_name='research-assistant',\n    embedding=embeddings\n)\n```\n2. 문서 임베딩 및 저장\n3. 유사도 검색 구현 (similarity_search_with_score)\n4. 메타데이터 필터링 구현\n5. 검색 결과 재순위화",
        "testStrategy": "1. 임베딩 생성 및 저장 검증\n2. 검색 정확도 테스트 (관련/비관련 쿼리)\n3. 메타데이터 필터링 정확성\n4. 검색 성능 벤치마크 (응답 시간)\n5. 인덱스 크기별 스케일링 테스트",
        "priority": "high",
        "dependencies": [
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Agent와 RAG 시스템 통합",
        "description": "LangChain Agent가 RAG 시스템을 활용하여 문서 기반 답변을 생성하도록 통합",
        "details": "1. RAG Tool 구현:\n```python\nfrom langchain.tools import Tool\nfrom langchain.chains import RetrievalQA\n\nretrieval_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    retriever=vectorstore.as_retriever(\n        search_kwargs={'k': 5}\n    ),\n    return_source_documents=True\n)\n\nrag_tool = Tool(\n    name='document_search',\n    description='Search through uploaded documents',\n    func=retrieval_chain.run\n)\n\nagent = create_react_agent(\n    llm=llm,\n    tools=[rag_tool],\n    prompt=react_prompt\n)\n```\n2. Context injection 메커니즘\n3. Source attribution 구현\n4. Agent의 RAG 활용 전략 최적화\n5. 하이브리드 응답 생성 (일반 지식 + 문서 정보)",
        "testStrategy": "1. 문서 기반 질문 응답 정확성\n2. 소스 인용 정확성 검증\n3. 컨텍스트 관련성 테스트\n4. 문서 없는 질문 처리 검증\n5. 멀티 문서 통합 답변 품질 테스트",
        "priority": "high",
        "dependencies": [
          2,
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "LangChain Tools 프레임워크 구현",
        "description": "웹 검색, 코드 실행 등 다양한 도구를 Agent가 활용할 수 있도록 Tool 시스템 구축",
        "details": "1. Tool Registry 구현:\n```python\nfrom langchain.tools import Tool\nfrom langchain_community.tools import SerperAPIWrapper\nfrom langchain.tools.python.tool import PythonREPLTool\n\nclass ToolRegistry:\n    def __init__(self):\n        self.tools = []\n        \n    def register_default_tools(self):\n        # Web Search Tool\n        search = SerperAPIWrapper()\n        self.tools.append(Tool(\n            name='web_search',\n            description='Search the web for current information',\n            func=search.run\n        ))\n        \n        # Python REPL Tool\n        python_tool = PythonREPLTool()\n        self.tools.append(python_tool)\n        \n        # Custom tools...\n        \n    def get_tools(self):\n        return self.tools\n```\n2. Tool 선택 최적화 로직\n3. Tool 실행 결과 파싱 및 검증\n4. 안전한 코드 실행 환경 (sandboxing)\n5. Tool 사용 로깅 및 모니터링",
        "testStrategy": "1. 각 Tool 개별 기능 테스트\n2. Tool 선택 정확성 검증\n3. 코드 실행 보안 테스트 (악성 코드 차단)\n4. Tool 실행 실패 처리 검증\n5. 멀티 Tool 연계 사용 시나리오 테스트",
        "priority": "medium",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "연구 세션 관리 시스템 구현",
        "description": "사용자별 연구 세션을 관리하고 대화 히스토리를 저장하는 시스템 구축",
        "details": "1. 데이터 모델 구현 (SQLite + Prisma):\n```typescript\n// schema.prisma\nmodel ResearchSession {\n  id        String   @id @default(cuid())\n  userId    String\n  topic     String\n  status    String   @default('active')\n  createdAt DateTime @default(now())\n  messages  Message[]\n  artifacts Artifact[]\n}\n\nmodel Message {\n  id           String    @id\n  sessionId    String\n  role         String\n  content      String\n  reasoning    Json?\n  toolsUsed    Json[]\n  timestamp    DateTime @default(now())\n  session      ResearchSession @relation(fields: [sessionId], references: [id])\n}\n```\n2. Session API 엔드포인트 구현\n3. 메시지 히스토리 관리\n4. 세션 복구 메커니즘\n5. 세션별 컨텍스트 격리",
        "testStrategy": "1. 세션 생성/조회/업데이트 테스트\n2. 메시지 저장 및 검색 정확성\n3. 동시 세션 처리 테스트\n4. 세션 복구 기능 검증\n5. 데이터베이스 트랜잭션 무결성 테스트",
        "priority": "medium",
        "dependencies": [
          3,
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "고급 UI/UX 기능 구현",
        "description": "사고 과정 시각화, 진행률 표시, 구조화된 결과 표시 등 고급 UI 기능 구현",
        "details": "1. 사고 과정 시각화 컴포넌트:\n```typescript\n// ThinkingProcess.tsx\nimport { Card } from '@/components/ui/card';\nimport { Brain, Search, FileText } from 'lucide-react';\n\ninterface ThoughtStep {\n  type: 'reasoning' | 'action' | 'observation';\n  content: string;\n  timestamp: Date;\n}\n\nexport function ThinkingProcess({ steps }: { steps: ThoughtStep[] }) {\n  return (\n    <Card className='p-4'>\n      <div className='space-y-2'>\n        {steps.map((step, i) => (\n          <div key={i} className='flex gap-2'>\n            {step.type === 'reasoning' && <Brain />}\n            {step.type === 'action' && <Search />}\n            {step.type === 'observation' && <FileText />}\n            <div>{step.content}</div>\n          </div>\n        ))}\n      </div>\n    </Card>\n  );\n}\n```\n2. 진행률 표시 (Progress bar, Skeleton loading)\n3. 마크다운 렌더링 (코드 하이라이팅 포함)\n4. 파일 업로드 UI (drag & drop)\n5. 소스 인용 표시 컴포넌트",
        "testStrategy": "1. 컴포넌트 렌더링 테스트\n2. 실시간 업데이트 동작 검증\n3. 다양한 마크다운 포맷 렌더링 테스트\n4. 파일 업로드 기능 테스트 (다양한 형식/크기)\n5. 반응형 디자인 테스트",
        "priority": "medium",
        "dependencies": [
          3,
          8
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "성능 최적화 및 프로덕션 준비",
        "description": "캐싱, 모델 전환, 비동기 처리 등 성능 최적화 및 배포 준비",
        "details": "1. Redis 캐싱 구현:\n```python\nimport redis\nimport json\nfrom functools import wraps\n\nredis_client = redis.Redis()\n\ndef cache_response(ttl=3600):\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            cache_key = f'{func.__name__}:{str(args)}:{str(kwargs)}'\n            cached = redis_client.get(cache_key)\n            if cached:\n                return json.loads(cached)\n            \n            result = await func(*args, **kwargs)\n            redis_client.setex(cache_key, ttl, json.dumps(result))\n            return result\n        return wrapper\n    return decorator\n```\n2. 모델 전환 로직 (GPT-4o-mini ↔ GPT-4o)\n3. 백그라운드 작업 큐 (Celery)\n4. API rate limiting\n5. 에러 추적 (Sentry)\n6. 배포 설정 (Vercel + Railway)",
        "testStrategy": "1. 캐시 히트율 측정\n2. 모델 전환 정확성 테스트\n3. 부하 테스트 (동시 사용자 처리)\n4. 응답 시간 벤치마크\n5. 에러 복구 시나리오 테스트",
        "priority": "low",
        "dependencies": [
          6,
          7,
          9
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-10T12:37:13.782Z",
      "updated": "2025-07-20T03:40:44.888Z",
      "description": "Tasks for master context"
    }
  }
}